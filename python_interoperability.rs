use numpy::ndarray::ArrayD;
use numpy::{IntoPyArray, PyArray1};
use pyo3::prelude::*;
use pyo3::wrap_pyfunction;
use std::sync::Arc;
use tch::{nn, Device, Tensor};

// Struct to represent an audio generator
struct AudioGenerator {
    model: Arc<tch::CModule>,
}

impl AudioGenerator {
    /// Constructor to create a new audio generator with a pre-trained model
    ///
    /// # Arguments
    ///
    /// * `model_path` - The path to the pre-trained PyTorch model file.
    ///
    /// # Returns
    ///
    /// * `Result<Self, Box<dyn std::error::Error>>` - The AudioGenerator instance or an error.
    ///
    /// # Possible Errors
    ///
    /// * `PyIOError` - If the model file cannot be loaded.
    fn new(model_path: &str) -> Result<Self, Box<dyn std::error::Error>> {
        // Attempt to load the pre-trained model
        let model = tch::CModule::load(model_path).map_err(|e| {
            format!("Failed to load model from {}: {}", model_path, e)
        })?;
        Ok(Self {
            model: Arc::new(model),
        })
    }

    /// Method to generate audio samples from a given input tensor
    ///
    /// # Arguments
    ///
    /// * `input` - The input tensor for the model.
    ///
    /// # Returns
    ///
    /// * `Tensor` - The output tensor generated by the model.
    ///
    /// # Possible Errors
    ///
    /// * `PyRuntimeError` - If the forward pass of the model fails.
    fn generate(&self, input: &Tensor) -> Tensor {
        // Perform a forward pass using the model
        self.model
            .forward_ts(&[input.unsqueeze(0)])  // Add batch dimension
            .unwrap_or_else(|e| panic!("Model forward pass failed: {}", e))  // Handle error
            .squeeze()  // Remove batch dimension
    }
}

// Python module to expose the audio generator functionality
#[pymodule]
fn python_interoperability(_py: Python, m: &PyModule) -> PyResult<()> {
    /// Define a Python class for the audio generator
    #[pyo3(text_signature = "(model_path)")]
    #[pyclass(name = "AudioGenerator")]
    struct PyAudioGenerator {
        #[pyo3(get)]
        generator: AudioGenerator,
    }

    // Implement Python methods for the audio generator class
    #[pymethods]
    impl PyAudioGenerator {
        /// Constructor to create a new audio generator from a model path
        ///
        /// # Arguments
        ///
        /// * `model_path` - The path to the pre-trained PyTorch model file.
        ///
        /// # Returns
        ///
        /// * `PyResult<Self>` - The PyAudioGenerator instance or a Python error.
        ///
        /// # Possible Errors
        ///
        /// * `PyValueError` - If the AudioGenerator cannot be created.
        #[new]
        fn new(model_path: &str) -> PyResult<Self> {
            let generator = AudioGenerator::new(model_path).map_err(|e| {
                PyErr::new::<pyo3::exceptions::PyValueError, _>(format!("Failed to create AudioGenerator: {}", e))
            })?;
            Ok(Self { generator })
        }

        /// Method to generate audio samples from a NumPy array
        ///
        /// # Arguments
        ///
        /// * `input` - The input NumPy array.
        ///
        /// # Returns
        ///
        /// * `PyResult<Py<PyArray1<f32>>>` - The generated audio samples as a NumPy array or a Python error.
        ///
        /// # Possible Errors
        ///
        /// * `PyValueError` - If the input cannot be converted to a Tensor.
        /// * `PyRuntimeError` - If the audio generation fails.
        fn generate(&self, input: &PyArray1<f32>) -> PyResult<Py<PyArray1<f32>>> {
            // Convert the input NumPy array to a PyTorch tensor
            let input_tensor = Tensor::of_slice(input.as_slice().unwrap()).to(Device::Cpu);
            // Handle potential error if input conversion fails
            if input_tensor.is_empty() {
                return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>("Failed to convert input to Tensor"));
            }

            // Generate audio samples using the AudioGenerator
            let output_tensor = self.generator.generate(&input_tensor);
            // Convert the output tensor to a NumPy array
            let output_array = output_tensor.try_into().unwrap();
            Ok(output_array.into_pyarray(input.py()).to_owned())
        }
    }

    // Add the audio generator class to the Python module
    m.add_class::<PyAudioGenerator>()?;
    Ok(())
}
